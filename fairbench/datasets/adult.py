# fairbench/datasets/adult.py
import pandas as pd, numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from ..utils.trainval import split_train_val
from .shrink import shrink_smallest_by_global_frac

def _fetch_adult(folder):
    import pandas as pd, numpy as np

    path = folder + "adult.csv"
    df = pd.read_csv(path)

    # 0) ê°€ë²¼ìš´ ì •ë¦¬
    df.columns = [c.strip() for c in df.columns]

    # 1) ì»¬ëŸ¼ ë³„ì¹­ â†’ í‘œì¤€ëª…ìœ¼ë¡œ í†µì¼ (ì†Œë¬¸ì ë¹„êµ)
    lower = {c.lower(): c for c in df.columns}

    def alias(old_keys, new_key):
        # old_keys: ì†Œë¬¸ì í›„ë³´ë“¤, new_key: ìµœì¢… ì»¬ëŸ¼ëª…(ì •í™•íˆ ì´ ì´ë¦„ì„ ì“°ê²Œ ë¨)
        for k in old_keys:
            if k in lower:
                src = lower[k]
                if new_key not in df.columns:
                    df.rename(columns={src: new_key}, inplace=True)
                # ì´ë¯¸ new_keyê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ê³  ì¢…ë£Œ
                return

    # ì„±ë³„: gender -> sex
    alias(["gender", "sex"], "sex")
    # êµìœ¡ì—°ì°¨: educational-num -> education-num
    alias(["educational-num", "education_num", "educational_num", "education-num"], "education-num")
    # ê·¼ë¡œì‹œê°„: hours_per_week/hoursperweek -> hours-per-week
    alias(["hours_per_week", "hoursperweek", "hours-per-week"], "hours-per-week")
    # ìë³¸ì´ë“/ì†ì‹¤: ë³€í˜• â†’ í‘œì¤€ í•˜ì´í”ˆ ì´ë¦„
    alias(["capital_gain", "capitalgain", "capital-gain"], "capital-gain")
    alias(["capital_loss", "capitalloss", "capital-loss"], "capital-loss")
    # ì¶œì‹ êµ­: native_country -> native-country
    alias(["native_country", "native-country"], "native-country")
    # í˜¼ì¸ìƒíƒœ: marital_status -> marital-status
    alias(["marital_status", "marital-status"], "marital-status")

    # 2) íƒ€ê¹ƒ/íŠ¹ì§• ë¶„ë¦¬
    y = (df["income"].astype(str).str.strip() == ">50K").astype(int).values
    X = df.drop(columns=["income"]).copy()

    # 3) ë¬¸ìì—´ ì •ë¦¬
    for c in X.select_dtypes(include=["object"]).columns:
        X[c] = (
            X[c].astype(str).str.strip()
                .replace("?", np.nan)
                .fillna("Unknown")
        )
    return X, y


def _extended_sensitive_from_adult_df(X: pd.DataFrame) -> pd.DataFrame:
    def has(c): return c in X.columns
    S = {}

    # --- required binaries ---
    if has("sex"):
        s = X["sex"].astype(str).str.strip()
        S["sex_Male"] = (s == "Male").astype(int)

    if has("race"):
        r = X["race"].astype(str).str.strip()
        S["race_White"] = (r == "White").astype(int)  # White vs not-White (single binary)

    if has("age"):
        age = pd.to_numeric(X["age"], errors="coerce")
        S["age_ge_40"] = (age >= 40).astype(int)  # â‰¥40 vs <40 (single binary)

    if has("marital-status"):
        ms = X["marital-status"].astype(str).str.strip()
        S["married"] = ms.isin({"Married-civ-spouse", "Married-AF-spouse"}).astype(int)  # married vs not

    # --- other binaries (ì´ë¯¸ ëª¨ë‘ 0/1 í˜•íƒœ) ---
    if has("education-num"):
        edu = pd.to_numeric(X["education-num"], errors="coerce").fillna(0)
        S["edu_bachelor_plus"] = (edu >= 13).astype(int)

    if has("native-country"):
        nc = X["native-country"].astype(str).str.strip()
        S["native_US"] = (nc == "United-States").astype(int)

    if has("workclass"):
        wc = X["workclass"].astype(str).str.strip()
        S["work_gov"]     = wc.isin({"Federal-gov","State-gov","Local-gov"}).astype(int)
        S["work_private"] = (wc == "Private").astype(int)

    if has("occupation"):
        occ = X["occupation"].astype(str).str.strip()
        S["occ_white_collar"] = occ.isin({
            "Prof-specialty","Exec-managerial","Tech-support"
        }).astype(int)
        S["occ_blue_collar"]  = occ.isin({
            "Craft-repair","Machine-op-inspct","Handlers-cleaners",
            "Farming-fishing","Transport-moving","Priv-house-serv"
        }).astype(int)

    if has("hours-per-week"):
        hpw = pd.to_numeric(X["hours-per-week"], errors="coerce").fillna(0)
        S["hours_ge_50"] = (hpw >= 50).astype(int)

    if has("capital-gain"):
        cg = pd.to_numeric(X["capital-gain"], errors="coerce").fillna(0)
        S["cap_gain_pos"] = (cg > 0).astype(int)

    if has("capital-loss"):
        cl = pd.to_numeric(X["capital-loss"], errors="coerce").fillna(0)
        S["cap_loss_pos"] = (cl > 0).astype(int)

    if has("relationship"):
        rel = X["relationship"].astype(str).str.strip()
        S["rel_husband"] = (rel == "Husband").astype(int)

    S_df = pd.DataFrame(S).astype(int)
    if S_df.shape[1] == 0 and has("sex"):
        S_df = pd.DataFrame({"sex_Male": (X["sex"].astype(str).str.strip() == "Male").astype(int)})
    return S_df


def _filter_sensitive_by_keys(S_df: pd.DataFrame, sens_keys) -> pd.DataFrame:
    """
    sens_keysë¡œ S_df ì»¬ëŸ¼ ì„ íƒ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ + ë™ì˜ì–´ ì§€ì› + ê°•ì œ í¬í•¨ ë³´ì •).
    ì§€ì›:
      - ì •í™• ì´ë¦„ (ì˜ˆ: 'sex_Male')
      - ì ‘ë‘ì‚¬* (ì˜ˆ: 'sex_*')
      - ì›ë³¸ í‚¤/ë™ì˜ì–´ (ì˜ˆ: 'sex','gender' â†’ 'sex_*'; 'marital-status','marital','married' â†’ 'married')
      - ì œì™¸: '-race_*'
      - íŠ¹ìˆ˜: 'all'/'*' â†’ ì „ì²´ ìœ ì§€
    """
    import re

    if sens_keys is None:
        return S_df

    # ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ í—ˆìš©
    if isinstance(sens_keys, str):
        tokens = [t.strip() for t in sens_keys.split(",") if t.strip()]
    elif isinstance(sens_keys, (list, tuple, set)):
        tokens = [str(t).strip() for t in sens_keys if str(t).strip()]
    else:
        return S_df
    if not tokens:
        return S_df

    cols = list(S_df.columns)
    cols_lc = {c.lower(): c for c in cols}  # lc â†’ original

    def _starts_with_icase(c: str, pref: str) -> bool:
        return c.lower().startswith(pref.lower())

    # ë™ì˜ì–´/ì›ë³¸í‚¤ â†’ ì ‘ë‘ì‚¬/ë‹¨ì¼ëª… (ì†Œë¬¸ì í‚¤)
    raw2prefix_icase = {
        "sex": "sex_",
        "gender": "sex_",
        "race": "race_",
        "age": "age_",
        "marital-status": "married",   # ë‹¨ì¼ëª…
        "marital": "married",
        "married": "married",
        "education-num": "edu_",
        "native-country": "native_",
        "workclass": "work_",
        "occupation": "occ_",
        "hours-per-week": "hours_",
        "capital-gain": "cap_gain_",
        "capital-loss": "cap_loss_",
        "relationship": "rel_",
    }

    include, exclude = set(), set()

    def expand(tok: str):
        neg = tok.startswith("-")
        t = tok[1:] if neg else tok
        t_lc = t.lower()
        matched = set()

        # (1) ì •í™• ëª…ì¹­
        if t_lc in cols_lc:
            matched.add(cols_lc[t_lc])

        # (2) ì ‘ë‘ì‚¬*
        if t.endswith("*"):
            pref = t[:-1]
            matched |= {c for c in cols if _starts_with_icase(c, pref)}

        # (3) ì›ë³¸ í‚¤/ë™ì˜ì–´ â†’ ì ‘ë‘ì‚¬/ë‹¨ì¼ëª…
        if t_lc in raw2prefix_icase:
            pref = raw2prefix_icase[t_lc]
            if pref.endswith("_"):  # ì ‘ë‘ì‚¬
                matched |= {c for c in cols if _starts_with_icase(c, pref)}
            else:                   # ë‹¨ì¼ëª… (ì˜ˆ: married)
                if pref.lower() in cols_lc:
                    matched.add(cols_lc[pref.lower()])

        # (4) regex:
        if t_lc.startswith("regex:"):
            pat = t[6:]
            try:
                rgx = re.compile(pat, re.IGNORECASE)
                matched |= {c for c in cols if rgx.search(c)}
            except re.error:
                pass

        return ("exclude", matched) if neg else ("include", matched)

    for tok in tokens:
        kind, m = expand(tok)
        if kind == "include":
            include |= m
        else:
            exclude |= m

    selected = (include or set(cols)) - exclude

    # ğŸ”’ ê°•ì œ í¬í•¨ ë³´ì •: ì‚¬ìš©ìê°€ sex/genderë¥¼ ìš”ì²­í–ˆëŠ”ë° ë§¤ì¹­ì´ 0ê°œë¼ë©´ 'sex_Male'ì„ í¬í•¨
    toks_lc = [t.lower().lstrip("-") for t in tokens]
    wants_sex = any(t in ("sex", "gender", "sex_*", "gender_*") for t in toks_lc)
    if wants_sex and not any(c.lower().startswith("sex_") for c in selected):
        if "sex_Male" in cols:
            selected.add("sex_Male")
        else:
            # í˜¹ì‹œ ì†Œë¬¸ì ë³€í˜•ìœ¼ë¡œ ì¡´ì¬í•  ë•Œë„ ì¼€ì–´
            for c in cols:
                if c.lower() == "sex_male":
                    selected.add(c)
                    break

    if not selected:
        # ì•ˆì „ fallback
        if "sex_Male" in cols:
            selected = {"sex_Male"}
        else:
            selected = {cols[0]} if cols else set()

    ordered = [c for c in cols if c in selected]

    # ë””ë²„ê·¸ ë¡œê·¸
    print(f"[sens_keys] tokens={tokens}")
    print(f"[sens_keys] selected={ordered}")

    return S_df[ordered]


def _infer_raw_cols_from_S(selected_S_cols, X: pd.DataFrame) -> list:
    """
    ì„ íƒëœ S ì»¬ëŸ¼ë“¤ë¡œë¶€í„° ì–´ë–¤ 'ì›ë³¸(raw) ì»¬ëŸ¼'ì„ ì‚¬ìš©í–ˆëŠ”ì§€ ì¶”ì •.
    x_sensitive='drop'ì¼ ë•Œ í•´ë‹¹ raw ì»¬ëŸ¼ë§Œ ì œê±°í•˜ë„ë¡ ì‚¬ìš©.
    """
    raws = set()
    for c in selected_S_cols:
        if c.startswith("sex_"): raws.add("sex")
        elif c.startswith("race_"): raws.add("race")
        elif c.startswith("age_"): raws.add("age")
        elif c == "married": raws.add("marital-status")
        elif c.startswith("edu_"): raws.add("education-num")
        elif c.startswith("native_"): raws.add("native-country")
        elif c.startswith("work_"): raws.add("workclass")
        elif c.startswith("occ_"): raws.add("occupation")
        elif c.startswith("hours_"): raws.add("hours-per-week")
        elif c.startswith("cap_gain_"): raws.add("capital-gain")
        elif c.startswith("cap_loss_"): raws.add("capital-loss")
        elif c.startswith("rel_"): raws.add("relationship")
    return [c for c in raws if c in X.columns]


def load_adult(args):
    X, y = _fetch_adult(folder = args.data_dir)
    S = _extended_sensitive_from_adult_df(X)

    sens_keys = getattr(args, "sens_keys", None)
    S = _filter_sensitive_by_keys(S, sens_keys)

    # ğŸ” í™•ì¸ ë¡œê·¸ (ë°˜ë“œì‹œ ì°í˜)
    print(f"[adult] S columns after filter = {list(S.columns)}")

    # (ì„ íƒ) ê¸°ëŒ€ í‚¤ë¥¼ ì¤¬ë‹¤ë©´ ë³´ì¥ìš© ì–´ì„¤ì…˜ (ì›í•˜ë©´ ì£¼ì„ í•´ì œ)
    # expected = {"sex_Male","race_White","age_ge_40","married"}
    # if sens_keys and all(k in str(sens_keys).lower() for k in ["sex","race","age","marital"]):
    #     assert set(S.columns) == expected, f"Expected {expected}, got {set(S.columns)}"

    mode = getattr(args, "x_sensitive", "drop")

    sens_raw_all = [c for c in [
        "sex","race","age","marital-status",
    ] if c in X.columns]

    if getattr(args, "sens_keys", None):
        raw_to_drop = _infer_raw_cols_from_S(S.columns, X)
    else:
        raw_to_drop = sens_raw_all

    if mode == "drop":
        # ğŸ’¡ sens_keysë¥¼ ì¼ë‹¤ë©´ raw_to_dropë§Œ ë“œë¡­í•˜ëŠ” ê²Œ ì¼ê´€ì 
        X_for_fe = X.drop(columns=raw_to_drop, errors="ignore")
    elif mode == "concat":
        try:
            raw_to_drop = _infer_raw_cols_from_S(S.columns, X)
        except Exception:
            raw_to_drop = sens_raw_all
        X_for_fe = X.drop(columns=[c for c in raw_to_drop if c in X.columns])
    else:
        X_for_fe = X.copy()

    # --- FE ---
    cat = X_for_fe.select_dtypes(include=["object"]).columns.tolist()
    num = X_for_fe.select_dtypes(exclude=["object"]).columns.tolist()

    enc = OneHotEncoder(sparse=False, handle_unknown="ignore")
    X_cat = pd.DataFrame(enc.fit_transform(X_for_fe[cat]))
    X_cat.columns = enc.get_feature_names_out(cat)

    scaler = StandardScaler()
    X_num = pd.DataFrame(scaler.fit_transform(X_for_fe[num]), columns=num)

    Xp = pd.concat([X_num, X_cat], axis=1)

    if mode == "concat":
        Xp = pd.concat([Xp.reset_index(drop=True), S.reset_index(drop=True)], axis=1)
        Xp = Xp.loc[:, ~Xp.columns.duplicated()]

    # ===== ì „ì²´ shrink í›„ split =====
    seed = getattr(args, "seed", 42)
    shrink_frac = float(getattr(args, "shrink_smallest_frac", 1.0))
    shrink_seed = getattr(args, "shrink_seed", seed)
    if shrink_frac != 1.0:
        # âœ… S_df â†’ Së¡œ ìˆ˜ì •
        Xp, y, S, shrink_info = shrink_smallest_by_global_frac(
            Xp, y, S, frac=shrink_frac, seed=shrink_seed
        )
    else:
        shrink_info = {"shrink_applied": False}

    # --- split ---
    X_tr, X_te, y_tr, y_te, S_tr, S_te = train_test_split(
        Xp, y, S, test_size=0.2, random_state=seed, stratify=y
    )
    X_tr, X_va, y_tr, y_va, S_tr, S_va = split_train_val(
        X_tr, y_tr, S_tr, val_size=0.2, seed=seed
    )

    print(f"[adult] final S_train cols = {list(S_tr.columns)}")

    return dict(
        X_train=X_tr, y_train=y_tr, S_train=S_tr,
        X_val=X_va,   y_val=y_va,   S_val=S_va,
        X_test=X_te,  y_test=y_te,  S_test=S_te,
        type="tabular",
        dataset="adult",  # ìˆìœ¼ë©´ CSV ê²½ë¡œë„ ê¹”ë”
        meta=dict(
            x_sensitive_mode=mode,
            sens_keys=(sens_keys if sens_keys is not None else "default"),
            used_S_cols=list(S.columns),
            dropped_cols=(raw_to_drop if mode=="drop" else []),
        ),
    )

